{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cacb3ed-9ff5-436c-a970-1cb8810c9b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae82f91-e9b5-4e08-b0a9-fdc45e32e02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RlAgent:\n",
    "    \"\"\"RL agent for the Roomba\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.q = np.zeros((16*16, 4), dtype=\"float64\") # to be corrected\n",
    "        self.state = 0\n",
    "        self.next_state = 0\n",
    "        self.reward = 0\n",
    "        self.action = 0\n",
    "        self.turn = 0\n",
    "        self.epsilon = 1\n",
    "        self.alpha = 0.1\n",
    "        self.gamma = 0.9\n",
    "        self.number_of_states = 11 # to be corrected\n",
    "        self.number_of_actions = 4 #  to be corrected\n",
    "\n",
    "    def get_number_of_states(self):\n",
    "        return self.number_of_states\n",
    "\n",
    "    def get_number_of_actions(self):\n",
    "        return self.number_of_actions\n",
    "\n",
    "    def e_greedy(self, actions):\n",
    "        a_star_idx = np.argmax(actions)\n",
    "        rng = np.random.default_rng()\n",
    "        if self.epsilon <= rng.random():\n",
    "            return a_star_idx\n",
    "        else:\n",
    "            b = actions.size\n",
    "            idx = rng.integers(low=0, high=b)\n",
    "            return idx\n",
    "\n",
    "    def select_action(self, state):\n",
    "        self.turn += 1\n",
    "        # print(\"Turn = \", self.turn)\n",
    "        self.state = state\n",
    "        # print(\"State = \", self.state)\n",
    "        actions = self.q[state, ]\n",
    "        action = self.e_greedy(actions)\n",
    "        self.action = action\n",
    "        return action\n",
    "\n",
    "    def update_q(self, new_state, reward):\n",
    "        self.next_state = new_state\n",
    "        self.q[self.state, self.action] = reward + (self.gamma * max(self.q[new_state, ]))\n",
    "        f\"Turn = {self.turn} \\nQ = {self.q}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab678e4a-8049-4790-b459-6dd7ad2b5b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class RoombaEnv():\n",
    "\n",
    "    TERMINAL_STATE_GOOD = 4 #  to be corrected\n",
    "    TERMINAL_STATE_BAD = 7 #  to be corrected\n",
    "    START_STATE = 8 #  to be corrected\n",
    "    NUMBER_OF_STATES = 11 #  to be corrected\n",
    "    NUMBER_OF_ACTIONS = 4 #  to be corrected\n",
    "\n",
    "    def __init__(self, map, charging_location):\n",
    "        \"\"\"\n",
    "        Set class properties with environment constants\n",
    "        \"\"\"\n",
    "        self.terminal_states = (RoombaEnv.TERMINAL_STATE_GOOD, RoombaEnv.TERMINAL_STATE_BAD)\n",
    "        self.current_state = RoombaEnv.START_STATE\n",
    "        self.map = map\n",
    "        self.charge_loc = charging_location\n",
    "\n",
    "    def get_number_of_states(self) -> int:\n",
    "        # Environment constant pass thru\n",
    "        return RoombaEnv.NUMBER_OF_STATES\n",
    "\n",
    "    def get_number_of_actions(self) -> int:\n",
    "        # Environment constant pass thru\n",
    "        return RoombaEnv.NUMBER_OF_ACTIONS\n",
    "\n",
    "    def reset(self, start_state: int = START_STATE, es_flag: bool = False) -> int:\n",
    "        \"\"\"\n",
    "        Reset the state of the game to a determined start_state if es_flag is False\n",
    "        Otherwise if es_flag is True then reset game to a random start state\n",
    "        Return the resulting state for agent to act on.\n",
    "        \"\"\"\n",
    "        if es_flag:\n",
    "            start_state = random.randint(1, RoombaEnv.NUMBER_OF_STATES)\n",
    "        self.set_state(start_state)\n",
    "        return self.get_state()\n",
    "\n",
    "    def get_state(self) -> int:\n",
    "        \"\"\"\n",
    "        Return current environment state.\n",
    "        \"\"\"\n",
    "        return self.current_state\n",
    "\n",
    "    def set_state(self, state: int):\n",
    "        \"\"\"\n",
    "        Set the current environment state resulting from agent action.\n",
    "        \"\"\"\n",
    "        self.current_state = state\n",
    "\n",
    "    def execute_action(self, action: int) -> (int, float, bool):\n",
    "        \"\"\"\n",
    "        Given an action, determine the resulting next_state. \n",
    "        Based on next_state determine the resulting reward for getting there.\n",
    "        Update current environment state and find if it is an end state.\n",
    "        \"\"\"\n",
    "        current_state = self.get_state()\n",
    "        next_state = RoombaEnv.get_next_state(current_state, action)\n",
    "        reward = RoombaEnv.get_reward(next_state)\n",
    "        self.set_state(next_state)\n",
    "        done = self.get_terminal_flag()\n",
    "        return next_state, reward, done\n",
    "\n",
    "    def get_next_state(state: int, action: int) -> int:\n",
    "        \"\"\"\n",
    "        Deterministic\n",
    "        Given the current state and an action return the next state grid position\n",
    "        state: Grid with 3 rows, {1,2,3,4}, {5,6,null,7}, {8,9,10,11}\n",
    "        action: 'up'=0, 'down'=1, 'left'=2, 'right'=3\n",
    "        \"\"\"\n",
    "        # define grid as current state for key and tuple next states for value\n",
    "        grid = {1:(1,5,1,2), 2:(2,6,1,3), 3:(3,3,2,4), 4:(4,4,4,4), 5:(1,8,5,6),\n",
    "                6:(2,9,5,6), 7:(7,7,7,7), 8:(5,8,8,9), 9:(6,9,8,10), 10:(10,10,9,11),\n",
    "                11:(7,11,10,11)}\n",
    "        return grid[state][action]\n",
    "\n",
    "    def get_reward(next_state: int) -> float:\n",
    "        \"\"\"\n",
    "        Static function, given a state returns a deterministic reward.\n",
    "        Default is -1 unless given a terminal state providing 25 or -25.\n",
    "        \"\"\"\n",
    "        reward = -1.0\n",
    "        if next_state == RoombaEnv.TERMINAL_STATE_GOOD:\n",
    "            reward = 25.0\n",
    "        elif next_state == RoombaEnv.TERMINAL_STATE_BAD:\n",
    "            reward = -25.0\n",
    "\n",
    "        return reward\n",
    "\n",
    "    def get_terminal_flag(self) -> bool:\n",
    "        \"\"\"\n",
    "        Return if current state is in a list of set terminal states\n",
    "        \"\"\"\n",
    "        return self.get_state() in self.terminal_states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46e4929a-1a56-45c8-8cf0-02948e39c78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# # # # # # # # # # # # # # # #\n",
      "# . * . . . . . . . . . . . . #\n",
      "# * . . . . . . * . . . . . * #\n",
      "# . . . . . . * . * . . * . . #\n",
      "# . * . . . . . . . * . . . * #\n",
      "# . * * * . . . . . * * . . * #\n",
      "# * . * * * * . . * . . . . . #\n",
      "# . . * * . . . . . . * . * . #\n",
      "# . * . * . . * . * * . . . . #\n",
      "# . . . . * . . . . . . . . . #\n",
      "# * * . . . . . . . . . . * * #\n",
      "# * . . * . . . . . * . . . * #\n",
      "# . . . * . . . . . . * . * . #\n",
      "# . . . . . . . . . . * . . * #\n",
      "# . * . . * . * . . . . . @ * #\n",
      "# # # # # # # # # # # # # # # #\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def generate_roomba_map(dirt_probability=0.2):\n",
    "    \"\"\"\n",
    "    Generates a 16x16 tile map for a Roomba simulation.\n",
    "    \n",
    "    Args:\n",
    "    dirt_probability: The probability of a tile being dirty (float between 0 and 1).\n",
    "    \n",
    "    Returns:\n",
    "    A 2D list representing the map.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a 16x16 grid with walls around the perimeter\n",
    "    map = [['#' for _ in range(16)] for _ in range(16)]\n",
    "\n",
    "    # Choose a random side for the charging station\n",
    "    side = random.randint(0, 3)\n",
    "\n",
    "    # Place the charging station (@) on a random wall tile\n",
    "    rnd_pos = random.randint(1, 14)\n",
    "    start_pos = (rnd_pos, 1) # Default Left wall\n",
    "    if side == 0:  # Top\n",
    "        map[1][rnd_pos] = '@'\n",
    "        start_pos = (1, rnd_pos)\n",
    "    elif side == 1:  # Right\n",
    "        map[rnd_pos][14] = '@'\n",
    "        start_pos = (rnd_pos, 14)\n",
    "    elif side == 2:  # Bottom\n",
    "        map[14][rnd_pos] = '@'\n",
    "        start_pos = (14, rnd_pos)\n",
    "    else:  # Left\n",
    "        map[rnd_pos][1] = '@'\n",
    "      \n",
    "    for row in range(1, 15):\n",
    "        for col in range(1, 15):\n",
    "            if map[row][col] == '@':\n",
    "                continue\n",
    "            # Add a clear tile with a chance of dirt\n",
    "            if random.random() < dirt_probability:\n",
    "                map[row][col] = '*'\n",
    "            else:\n",
    "                map[row][col] = '.'\n",
    "\n",
    "    return map, start_pos\n",
    "\n",
    "# Example usage:\n",
    "room_map, charging_base = generate_roomba_map(dirt_probability=0.3)\n",
    "\n",
    "# Print the map\n",
    "for row in room_map:\n",
    "  print(' '.join(row)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d6d463-60fd-4166-8bbf-2ea37e7b70fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    environment = RoombaEnv(room_map, charging_base)\n",
    "    agent = RlAgent(charging_base)\n",
    "    # Check that the environment parameters match\n",
    "    if (environment.get_number_of_states() == agent.get_number_of_states()) and \\\n",
    "            (environment.get_number_of_actions() == agent.get_number_of_actions()):\n",
    "        # Play 100 games\n",
    "        for i in range(100):\n",
    "            # reset the game and observe the current state\n",
    "            current_state = environment.reset()\n",
    "            game_end = False\n",
    "            # Do until the game ends:\n",
    "            while not game_end:\n",
    "                action = agent.select_action(current_state)\n",
    "                new_state, reward, game_end = environment.execute_action(action)\n",
    "                agent.update_q(new_state, reward)\n",
    "                current_state = new_state\n",
    "        with open('Project1.txt', 'wt') as f:\n",
    "            print(agent.q, file=f)\n",
    "        print(\"\\nProgram completed successfully.\")\n",
    "    else:\n",
    "        print(\"Environment and Agent parameters do not match. Terminating program.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
